{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef00bb3-01bf-4787-a341-b808c6960047",
   "metadata": {},
   "source": [
    "# Training feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb2833-77f5-429a-a0e4-61a8929c5973",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We started with extracting as many EO measurements as that can be feasibly calculated from the growing season of interest. However, some of these measurements may be correlated because they describe similar or related properties of the crops.\n",
    "A good practice is to remove the highly coorelated features because they increase the complexity of a model without enhancing its prediction performance.\n",
    "\n",
    "Another common issue with labelled training data is class imbalance, i.e. it has skewed class proportions. During model training, the algorithm will optimize over all training data, hence imbalanced training data may lead to a biased model. For example, the model is more likely to mis-classify a minority class as a majority class than the other way around.\n",
    "\n",
    "In some cases, distribution of the training data is designed to match the true distribution of the classes, and the prediction is expected to bias against an infrequent class. In some other cases, accuray requirements are different for different classes. It is then desirable to adjust the porportions of the training labels to include more points for classes where commission error is preferred over omission error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859405c-985a-4659-b430-4fed3a097c61",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook demonstrates how to explore class imbalance and correlations between the features extracted in the [feature extracion notebook](3_Training_feature_extraction.ipynb), and adjust the data before using it to train a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a802cd5-b9f8-4a64-9ab2-9ef9bc3f093a",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b8a09-b68a-47d2-903d-60c9af6483bf",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88f8ae5-f838-4e93-9f3d-dadd4ada8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from odc.io.cgroups import get_cpu_quota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9e32e-be5c-41ae-9089-a5d3115e0750",
   "metadata": {},
   "source": [
    "## Load training data and label dictionary\n",
    "\n",
    "We will load the training data saved from the [feature extracion notebook](3_Training_feature_extraction.ipynb), along with the mapping between crop labels and the numerical classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77e5b9b-e0ab-45f9-945e-82aa32bc5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data file from previous step\n",
    "data_path = \"Results/single_crops_merged_training_features_2021_all.csv\"\n",
    "\n",
    "# Dictionary with class labels from previous step\n",
    "labels_path = \"Results/class_labels.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672ef81-db8e-47e2-9fb2-7a5d766d9edd",
   "metadata": {},
   "source": [
    "### Inspect the label and feature columns\n",
    "\n",
    "As shown below, we have over 100 features extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4fe65-40bd-48ff-bf4a-cecd5e641315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "model_input = np.loadtxt(data_path)\n",
    "\n",
    "# load the column_names\n",
    "with open(data_path, \"r\") as file:\n",
    "    header = file.readline()\n",
    "\n",
    "# Remove comment symbol from header, then extract label and feature names\n",
    "column_names = header.split()[1:]\n",
    "\n",
    "label_col = column_names[0]\n",
    "feature_cols = column_names[1:]\n",
    "\n",
    "print(f\"Label column:\\n{label_col}\\n\")\n",
    "print(f\"Feature columns:\\n{feature_cols}\\n\")\n",
    "print('number of features: ',len(feature_cols))\n",
    "\n",
    "# Extract relevant indices from training data\n",
    "model_col_indices = [column_names.index(var_name) for var_name in column_names[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a36779-ad63-4e9e-90cd-4d84528b7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "model_input_df = pd.read_csv(data_path)\n",
    "model_input_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32011ea0-f65b-406f-abe4-90ef13aaa82d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13759/2168959339.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load the column_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the class label dictionary\n",
    "with open(labels_path, \"r\") as json_file:\n",
    "    labels_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f1926-b7f7-44d1-bfea-bba13d30304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Maize': 0, 'Others': 1, 'Sesame': 2, 'Soy': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4270c84-deaf-4e96-9d6b-23edc50dd098",
   "metadata": {},
   "source": [
    "## Class rebalancing\n",
    "\n",
    "We first inspect the number of samples per class and notice we have significant larger number of \"Others\" class than the single crop classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8482e0b-e8a9-4e86-bc43-11327ad76f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13759/102228288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Insert data into a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_input_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Investigate value counts for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_input_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_input' is not defined"
     ]
    }
   ],
   "source": [
    "# Insert data into a Pandas DataFrame\n",
    "model_input_df = pd.DataFrame(model_input, columns=column_names)\n",
    "# Investigate value counts for each class\n",
    "class_counts=model_input_df[label_col].value_counts()\n",
    "class_indices=class_counts.index\n",
    "labels_dict_inv={value: key for key, value in labels_dict.items()}\n",
    "class_legends=[labels_dict_inv[class_indices[i]] for i in range(len(class_indices))]\n",
    "plt.figure(figsize=(15,5))\n",
    "ax=plt.bar(class_legends,height=class_counts.to_numpy())\n",
    "plt.bar_label(ax)\n",
    "plt.gca().set_ylabel('Number of training samples')\n",
    "plt.gca().set_xlabel('Crop type')\n",
    "plt.gca().tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408358b-b6a0-4199-9eb9-9eab75c3f6c1",
   "metadata": {},
   "source": [
    "We then reduce the number of samples for classes with more than twice the number of any others. (**Check this statement against the code**)\n",
    "\n",
    "> We are not making all sample sizes same because we want to preserve the large number of Maize and Sesame samples to capture intra-class diversity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b414c1de-7ca1-44ef-93e5-f557b8d9fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 11147 of Others samples\n",
      "no balancing needed\n",
      "no balancing needed\n",
      "no balancing needed\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_counts)):\n",
    "    if class_counts.values[i]>10*class_counts.values[-1]:\n",
    "        n_samples_dropped=class_counts.values[i]-10*class_counts.values[-1]\n",
    "        print('dropping {} of {} samples'.format(n_samples_dropped,labels_dict_inv[class_indices[i]]))\n",
    "        model_input_df.drop(model_input_df[model_input_df[label_col]==class_indices[i]].sample(n=n_samples_dropped).index,\n",
    "                            axis=0,inplace=True)\n",
    "    else:\n",
    "        print('no balancing needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29387a3e-0a4d-4d64-be3e-b75dd5f32517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into features and labels\n",
    "X = model_input_df.drop(label_col, axis=1)[columns_to_use].values\n",
    "y = model_input_df[[label_col]].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede5f7e-9682-49ea-a4f6-872d24578ce0",
   "metadata": {},
   "source": [
    "## Drop correlated features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f615c56-f5d1-4c53-a177-7f41b5c97a03",
   "metadata": {},
   "source": [
    "### Create and visualize the correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93434b26-6872-4fad-bc13-2d416682bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = model_input_df.drop(label_col, axis=1)[columns_to_use]\n",
    "correlation_matrix = X_.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa8b37e-6ac5-4f3d-a52c-5fe74114734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d76b5c-714a-4f40-a678-d64acd03c4c0",
   "metadata": {},
   "source": [
    "We will define a function and set a threshold of 0.9 to remove correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e65c09-7e17-4dfa-831c-6fd7aae3bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95abbebe-ae8e-40cc-9972-40602489c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing correlated variables\n",
    "def DropCorrelatedFeatures(X_, removal_threshold=0.9):\n",
    "    to_drop = set()  # set of features to drop\n",
    "    correlation_matrix = X_.corr().abs()\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (correlation_matrix.iloc[i, j] >= removal_threshold) and (correlation_matrix.columns[j] not in to_drop):\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                to_drop.add(colname)\n",
    "    to_drop = list(to_drop)\n",
    "    X_dropped = X_.copy()\n",
    "    X_dropped = X_dropped.drop(to_drop, axis=1)\n",
    "    return X_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21693cc9-18ea-4f56-aba4-0c6125d0b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['blue_s2_Q4_2021', 'green_s2_Q4_2021', 'red_s2_Q4_2021',\n",
       "       'nir_s2_Q4_2021', 'swir_1_s2_Q4_2021', 'NDVI_s2_Q4_2021',\n",
       "       'MNDWI_s2_Q4_2021', 'blue_s2_Q1_2022', 'red_s2_Q1_2022',\n",
       "       'nir_s2_Q1_2022', 'swir_1_s2_Q1_2022', 'red_edge_1_s2_Q1_2022',\n",
       "       'NDVI_s2_Q1_2022', 'MNDWI_s2_Q1_2022', 'blue_s2_Q2_2022',\n",
       "       'green_s2_Q2_2022', 'red_s2_Q2_2022', 'nir_s2_Q2_2022',\n",
       "       'swir_1_s2_Q2_2022', 'NDVI_s2_Q2_2022', 'MNDWI_s2_Q2_2022',\n",
       "       'blue_s2_Q3_2022', 'red_s2_Q3_2022', 'nir_s2_Q3_2022',\n",
       "       'swir_1_s2_Q3_2022', 'red_edge_1_s2_Q3_2022', 'NDVI_s2_Q3_2022',\n",
       "       'MNDWI_s2_Q3_2022', 'blue_s2_annual_2021', 'red_s2_annual_2021',\n",
       "       'nir_s2_annual_2021', 'swir_1_s2_annual_2021',\n",
       "       'red_edge_1_s2_annual_2021', 'smad_s2_annual_2021',\n",
       "       'emad_s2_annual_2021', 'bcmad_s2_annual_2021', 'NDVI_s2_annual_2021',\n",
       "       'MNDWI_s2_annual_2021', 'blue_s2_semiannual_2021_07',\n",
       "       'nir_s2_semiannual_2021_07', 'smad_s2_semiannual_2021_07',\n",
       "       'emad_s2_semiannual_2021_07', 'bcmad_s2_semiannual_2021_07',\n",
       "       'NDVI_s2_semiannual_2021_07', 'blue_s2_semiannual_2022_01',\n",
       "       'swir_2_s2_semiannual_2022_01', 'red_edge_1_s2_semiannual_2022_01',\n",
       "       'red_edge_2_s2_semiannual_2022_01', 'smad_s2_semiannual_2022_01',\n",
       "       'emad_s2_semiannual_2022_01', 'bcmad_s2_semiannual_2022_01',\n",
       "       'NDVI_s2_semiannual_2022_01', 'MNDWI_s2_semiannual_2022_01',\n",
       "       'bs_mean_Q4_2021', 'pv_mean_Q4_2021', 'npv_mean_Q4_2021',\n",
       "       'ue_mean_Q4_2021', 'bs_mean_Q1_2022', 'pv_mean_Q1_2022',\n",
       "       'npv_mean_Q1_2022', 'ue_mean_Q1_2022', 'bs_mean_Q2_2022',\n",
       "       'npv_mean_Q2_2022', 'ue_mean_Q2_2022', 'bs_mean_Q3_2022',\n",
       "       'npv_mean_Q3_2022', 'ue_mean_Q3_2022', 'slope'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = model_input_df.drop(label_col, axis=1)[columns_to_use]\n",
    "X_dropped = DropCorrelatedFeatures(X_, removal_threshold=removal_threshold)\n",
    "print(\"# of features to keep:\", len(X_dropped.columns))\n",
    "X_dropped.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f671982-13e7-400a-9d87-658de47afbb5",
   "metadata": {},
   "source": [
    "## Save the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7df6a-3fc6-44eb-8a72-3977dbb6bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_features = pd.concat([model_input_df[label_col], X_dropped], axis = 1)\n",
    "\n",
    "output_features.to_csv(\"Results/single_crops_merged_training_features_2021_selected.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
